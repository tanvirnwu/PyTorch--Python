{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f204bb17",
   "metadata": {
    "papermill": {
     "duration": 0.006665,
     "end_time": "2023-10-31T01:18:04.722017",
     "exception": false,
     "start_time": "2023-10-31T01:18:04.715352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Why do we need to Save and Load Models**\n",
    "Saving and loading PyTorch models is a crucial aspect of deep learning projects. It allows you to preserve trained models for future use, share them with others, or continue training on them without starting from scratch. In this comprehensive guide, we will explore the techniques and best practices for saving and loading PyTorch models. Whether you are a machine learning practitioner, researcher, or enthusiast, understanding how to manage your models is essential for efficient and effective deep learning workflows. Let's dive into the world of model persistence and continuity with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b38dd72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:04.737002Z",
     "iopub.status.busy": "2023-10-31T01:18:04.736340Z",
     "iopub.status.idle": "2023-10-31T01:18:20.704547Z",
     "shell.execute_reply": "2023-10-31T01:18:20.702825Z"
    },
    "papermill": {
     "duration": 15.978996,
     "end_time": "2023-10-31T01:18:20.707329",
     "exception": false,
     "start_time": "2023-10-31T01:18:04.728333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_summary\r\n",
      "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\r\n",
      "Installing collected packages: torch_summary\r\n",
      "Successfully installed torch_summary-1.4.5\r\n"
     ]
    }
   ],
   "source": [
    "import torch              # Importing the PyTorch library\n",
    "import torch.nn as nn     # Importing the PyTorch neural network module\n",
    "import numpy as np        # Importing NumPy for numerical operations\n",
    "from torch.utils.data import Dataset, DataLoader  # Importing PyTorch data utilities\n",
    "!pip install torch_summary  # Installing the torch_summary package for model summary\n",
    "from torchsummary import summary  # Importing the summary function from torch_summary\n",
    "from torch.optim import SGD  # Importing the stochastic gradient descent optimizer from PyTorch\n",
    "import time  # Importing the time module for measuring time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a65aea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:20.722091Z",
     "iopub.status.busy": "2023-10-31T01:18:20.721420Z",
     "iopub.status.idle": "2023-10-31T01:18:20.727595Z",
     "shell.execute_reply": "2023-10-31T01:18:20.726323Z"
    },
    "papermill": {
     "duration": 0.016371,
     "end_time": "2023-10-31T01:18:20.729947",
     "exception": false,
     "start_time": "2023-10-31T01:18:20.713576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Determine the compute device (CPU or CUDA GPU) availability\n",
    "# and set the 'device' variable accordingly.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 'device' will be \"cuda\" if a GPU is available, otherwise, it will be \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19997b14",
   "metadata": {
    "papermill": {
     "duration": 0.006063,
     "end_time": "2023-10-31T01:18:20.742564",
     "exception": false,
     "start_time": "2023-10-31T01:18:20.736501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b6a365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:20.757655Z",
     "iopub.status.busy": "2023-10-31T01:18:20.757260Z",
     "iopub.status.idle": "2023-10-31T01:18:20.764640Z",
     "shell.execute_reply": "2023-10-31T01:18:20.763724Z"
    },
    "papermill": {
     "duration": 0.017042,
     "end_time": "2023-10-31T01:18:20.766671",
     "exception": false,
     "start_time": "2023-10-31T01:18:20.749629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataProcessing(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with input data (X) and labels (y).\n",
    "\n",
    "        Args:\n",
    "        - X: Input data as a NumPy array.\n",
    "        - y: Labels as a NumPy array.\n",
    "        \"\"\"\n",
    "        self.X = torch.tensor(X).float().to(device)  # Convert and move input data to the specified device (CPU or GPU)\n",
    "        self.y = torch.tensor(y).float().to(device)  # Convert and move labels to the specified device (CPU or GPU)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get a single data sample and its corresponding label by index.\n",
    "\n",
    "        Args:\n",
    "        - index: Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        A tuple containing the data sample and its label.\n",
    "        \"\"\"\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the total number of data samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "        The length of the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb53466",
   "metadata": {
    "papermill": {
     "duration": 0.005944,
     "end_time": "2023-10-31T01:18:20.778920",
     "exception": false,
     "start_time": "2023-10-31T01:18:20.772976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the below code, we generate a random dataset 'X' consisting of 10 samples, each with 2 features, where the values range from 0 to 10. We then calculate the sum of each row in 'X' to obtain row-wise sums, storing them in 'y' after reshaping to form a column vector. The resulting 'X' holds the original random integer data, while 'y' contains the computed row-wise sums. This data preprocessing step is often a crucial initial stage in many machine learning tasks, as it prepares the data for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf3d8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:20.792914Z",
     "iopub.status.busy": "2023-10-31T01:18:20.792559Z",
     "iopub.status.idle": "2023-10-31T01:18:20.805206Z",
     "shell.execute_reply": "2023-10-31T01:18:20.804168Z"
    },
    "papermill": {
     "duration": 0.022272,
     "end_time": "2023-10-31T01:18:20.807270",
     "exception": false,
     "start_time": "2023-10-31T01:18:20.784998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 4],\n",
       "        [6, 8],\n",
       "        [0, 9],\n",
       "        [6, 2],\n",
       "        [8, 9],\n",
       "        [4, 1],\n",
       "        [8, 0],\n",
       "        [4, 2],\n",
       "        [6, 8],\n",
       "        [3, 6]]),\n",
       " array([[ 4],\n",
       "        [14],\n",
       "        [ 9],\n",
       "        [ 8],\n",
       "        [17],\n",
       "        [ 5],\n",
       "        [ 8],\n",
       "        [ 6],\n",
       "        [14],\n",
       "        [ 9]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random integer data in the range [0, 10) with a shape of (10, 2)\n",
    "X = np.random.randint(0, 10, size=(10, 2))\n",
    "\n",
    "# Calculate the sum of each row along axis=1 to get row-wise sums\n",
    "row_sums = np.sum(X, axis=1)\n",
    "\n",
    "# Reshape the 'row_sums' array to have a column shape, effectively converting it to a column vector\n",
    "y = row_sums.reshape(-1, 1)\n",
    "\n",
    "# 'X' contains the original random integer data (10 samples, 2 features)\n",
    "# 'y' contains the row-wise sums of 'X' as a column vector\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0bebb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:20.821725Z",
     "iopub.status.busy": "2023-10-31T01:18:20.821339Z",
     "iopub.status.idle": "2023-10-31T01:18:20.918105Z",
     "shell.execute_reply": "2023-10-31T01:18:20.916877Z"
    },
    "papermill": {
     "duration": 0.107211,
     "end_time": "2023-10-31T01:18:20.920883",
     "exception": false,
     "start_time": "2023-10-31T01:18:20.813672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: tensor([6., 8.])\n",
      "Label 1: tensor([14.])\n",
      "Sample 0: tensor([0., 4.])\n",
      "Label 0: tensor([4.])\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the custom dataset 'DataProcessing' with input data 'X' and labels 'y'\n",
    "dp = DataProcessing(X, y)\n",
    "\n",
    "# Access the second data sample and its corresponding label (index 1)\n",
    "sample_1, label_1 = dp[1]\n",
    "\n",
    "# Access the first data sample and its corresponding label (index 0)\n",
    "sample_0, label_0 = dp[0]\n",
    "\n",
    "print(\"Sample 1:\", sample_1)\n",
    "print(\"Label 1:\", label_1)\n",
    "print(\"Sample 0:\", sample_0)\n",
    "print(\"Label 0:\", label_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6dff944",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:20.936744Z",
     "iopub.status.busy": "2023-10-31T01:18:20.935724Z",
     "iopub.status.idle": "2023-10-31T01:18:20.941521Z",
     "shell.execute_reply": "2023-10-31T01:18:20.940419Z"
    },
    "papermill": {
     "duration": 0.015726,
     "end_time": "2023-10-31T01:18:20.943422",
     "exception": false,
     "start_time": "2023-10-31T01:18:20.927696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataLoader named 'dloader' with the custom dataset 'dp'\n",
    "# Using a batch size of 2 and enabling data shuffling\n",
    "dloader = DataLoader(dp, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3545ff90",
   "metadata": {
    "papermill": {
     "duration": 0.006217,
     "end_time": "2023-10-31T01:18:20.956164",
     "exception": false,
     "start_time": "2023-10-31T01:18:20.949947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Creating Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94e7aeb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:20.971367Z",
     "iopub.status.busy": "2023-10-31T01:18:20.970688Z",
     "iopub.status.idle": "2023-10-31T01:18:20.981443Z",
     "shell.execute_reply": "2023-10-31T01:18:20.980485Z"
    },
    "papermill": {
     "duration": 0.021146,
     "end_time": "2023-10-31T01:18:20.983751",
     "exception": false,
     "start_time": "2023-10-31T01:18:20.962605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a neural network model using a sequential architecture\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 5),  \n",
    "    nn.ReLU(),        \n",
    "    nn.Linear(5, 1)  \n",
    ").to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f824ac31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:20.998936Z",
     "iopub.status.busy": "2023-10-31T01:18:20.998236Z",
     "iopub.status.idle": "2023-10-31T01:18:21.029679Z",
     "shell.execute_reply": "2023-10-31T01:18:21.028633Z"
    },
    "papermill": {
     "duration": 0.041808,
     "end_time": "2023-10-31T01:18:21.032136",
     "exception": false,
     "start_time": "2023-10-31T01:18:20.990328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 5]                   15\n",
      "├─ReLU: 1-2                              [-1, 5]                   --\n",
      "├─Linear: 1-3                            [-1, 1]                   6\n",
      "==========================================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 5]                   15\n",
       "├─ReLU: 1-2                              [-1, 5]                   --\n",
       "├─Linear: 1-3                            [-1, 1]                   6\n",
       "==========================================================================================\n",
       "Total params: 21\n",
       "Trainable params: 21\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a summary of the model's architecture by passing a sample input of shape (1, 2)\n",
    "summary(model, torch.zeros(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1168b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:21.048306Z",
     "iopub.status.busy": "2023-10-31T01:18:21.047539Z",
     "iopub.status.idle": "2023-10-31T01:18:21.052953Z",
     "shell.execute_reply": "2023-10-31T01:18:21.052195Z"
    },
    "papermill": {
     "duration": 0.016046,
     "end_time": "2023-10-31T01:18:21.055087",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.039041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a loss function (Mean Squared Error) and an optimizer (Stochastic Gradient Descent) for the model\n",
    "loss_fn = nn.MSELoss()  # Mean Squared Error loss function\n",
    "optimizer = SGD(model.parameters(), lr=0.001)  # Stochastic Gradient Descent (SGD) optimizer with a learning rate of 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b837ae8",
   "metadata": {
    "papermill": {
     "duration": 0.0065,
     "end_time": "2023-10-31T01:18:21.068255",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.061755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5ec4f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:21.083719Z",
     "iopub.status.busy": "2023-10-31T01:18:21.083091Z",
     "iopub.status.idle": "2023-10-31T01:18:21.257372Z",
     "shell.execute_reply": "2023-10-31T01:18:21.255888Z"
    },
    "papermill": {
     "duration": 0.185696,
     "end_time": "2023-10-31T01:18:21.260770",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.075074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Time = 0.16399168968200684 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store loss values\n",
    "loss_history = []\n",
    "\n",
    "# Record the start time for training\n",
    "start = time.time()\n",
    "\n",
    "# Iterate through 50 epochs\n",
    "for epoch in range(50):\n",
    "    # Iterate through mini-batches from the data loader\n",
    "    for X, y in dloader:\n",
    "        optimizer.zero_grad()       # Zero the gradients\n",
    "        y_pred = model(X)           # Forward pass to get predictions\n",
    "        loss_value = loss_fn(y_pred, y)  # Calculate the loss\n",
    "        loss_value.backward()       # Backpropagation to compute gradients\n",
    "        optimizer.step()            # Update model parameters using the optimizer\n",
    "        loss_history.append(loss_value.item())  # Append the loss value to the history\n",
    "\n",
    "# Record the end time for training\n",
    "end = time.time()\n",
    "\n",
    "# Print the total training time\n",
    "print(f\"Total Training Time = {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f205b8b",
   "metadata": {
    "papermill": {
     "duration": 0.008954,
     "end_time": "2023-10-31T01:18:21.284692",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.275738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Saving Model**\n",
    "In this code, we define a save_path where the model's state dictionary will be saved using torch.save. After saving the model, we use the du command to calculate and print the size of the saved model in megabytes (MB). The os.path.getsize function is used to determine the file size in bytes, which is then converted to MB for readability. This code helps to assess the storage requirements of the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cbf078d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:21.303308Z",
     "iopub.status.busy": "2023-10-31T01:18:21.302439Z",
     "iopub.status.idle": "2023-10-31T01:18:21.310917Z",
     "shell.execute_reply": "2023-10-31T01:18:21.309785Z"
    },
    "papermill": {
     "duration": 0.022249,
     "end_time": "2023-10-31T01:18:21.314832",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.292583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model on disk: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "# Define the path for saving the model\n",
    "save_path = \"mymodel.pth\"\n",
    "\n",
    "# Save the model's state_dict to the specified path\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "# Calculate and print the size of the saved model on disk\n",
    "import os\n",
    "model_size = os.path.getsize(save_path)\n",
    "print(f\"Size of the model on disk: {model_size / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860908a1",
   "metadata": {
    "papermill": {
     "duration": 0.007845,
     "end_time": "2023-10-31T01:18:21.330844",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.322999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Loading Model**\n",
    "Now we will load the same model that we just saved in the previous code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b6616a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:21.348201Z",
     "iopub.status.busy": "2023-10-31T01:18:21.347462Z",
     "iopub.status.idle": "2023-10-31T01:18:21.354891Z",
     "shell.execute_reply": "2023-10-31T01:18:21.354148Z"
    },
    "papermill": {
     "duration": 0.018035,
     "end_time": "2023-10-31T01:18:21.356909",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.338874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path for loading the pre-trained model\n",
    "load_path = \"mymodel.pth\"\n",
    "\n",
    "# Load the pre-trained model's state_dict into the model\n",
    "model.load_state_dict(torch.load(load_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8b9c0",
   "metadata": {
    "papermill": {
     "duration": 0.006769,
     "end_time": "2023-10-31T01:18:21.370735",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.363966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Prediction Using the Loaded Model**\n",
    "In this code, we generate random test data 'X_test' with the same characteristics as the training data. We calculate row-wise sums and reshape them to form 'y_test.' Then, we convert 'X_test' and 'y_test' to PyTorch tensors and move them to the specified device. Finally, we display the converted test data and labels. This prepares the test data for evaluation with our loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3686680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:21.387034Z",
     "iopub.status.busy": "2023-10-31T01:18:21.386354Z",
     "iopub.status.idle": "2023-10-31T01:18:21.396138Z",
     "shell.execute_reply": "2023-10-31T01:18:21.395326Z"
    },
    "papermill": {
     "duration": 0.02034,
     "end_time": "2023-10-31T01:18:21.398227",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.377887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 4.],\n",
       "         [2., 7.],\n",
       "         [3., 0.],\n",
       "         [6., 1.],\n",
       "         [9., 6.],\n",
       "         [2., 5.],\n",
       "         [7., 8.],\n",
       "         [2., 1.],\n",
       "         [5., 6.],\n",
       "         [5., 0.]]),\n",
       " tensor([[ 7.],\n",
       "         [ 9.],\n",
       "         [ 3.],\n",
       "         [ 7.],\n",
       "         [15.],\n",
       "         [ 7.],\n",
       "         [15.],\n",
       "         [ 3.],\n",
       "         [11.],\n",
       "         [ 5.]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random integer test data in the range [0, 10) with a shape of (10, 2)\n",
    "X_test = np.random.randint(0, 10, size=(10, 2))\n",
    "\n",
    "# Calculate the row-wise sum along axis=1\n",
    "row_sums = np.sum(X_test, axis=1)\n",
    "\n",
    "# Reshape the row_sums array to have a column shape\n",
    "y_test = row_sums.reshape(-1, 1)\n",
    "\n",
    "# Convert the test data and labels to PyTorch tensors and move them to the specified device (CPU or GPU)\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "y_test = torch.tensor(y_test).float().to(device)\n",
    "\n",
    "# Display the converted test data and labels\n",
    "X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea88ac90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:21.414734Z",
     "iopub.status.busy": "2023-10-31T01:18:21.414044Z",
     "iopub.status.idle": "2023-10-31T01:18:21.421110Z",
     "shell.execute_reply": "2023-10-31T01:18:21.420358Z"
    },
    "papermill": {
     "duration": 0.017813,
     "end_time": "2023-10-31T01:18:21.423263",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.405450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 7],\n",
       "        [15],\n",
       "        [ 7],\n",
       "        [15],\n",
       "        [ 3],\n",
       "        [11],\n",
       "        [ 5]], dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test data using the trained model\n",
    "y_test_pred = model(X_test)\n",
    "\n",
    "# Round the predictions to the nearest integer and convert to torch.int dtype\n",
    "y_test_pred = y_test_pred.round().to(dtype=torch.int)\n",
    "\n",
    "# Display the predicted labels for the test data\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc33c1b1",
   "metadata": {
    "papermill": {
     "duration": 0.007024,
     "end_time": "2023-10-31T01:18:21.438313",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.431289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba8183c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:21.455230Z",
     "iopub.status.busy": "2023-10-31T01:18:21.454793Z",
     "iopub.status.idle": "2023-10-31T01:18:21.460580Z",
     "shell.execute_reply": "2023-10-31T01:18:21.459557Z"
    },
    "papermill": {
     "duration": 0.01687,
     "end_time": "2023-10-31T01:18:21.462848",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.445978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(predicted_labels, true_labels):\n",
    "    # Convert predicted and true labels to numpy arrays if they are tensors\n",
    "    if torch.is_tensor(predicted_labels):\n",
    "        predicted_labels = predicted_labels.cpu().numpy()\n",
    "    if torch.is_tensor(true_labels):\n",
    "        true_labels = true_labels.cpu().numpy()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    num_correct = (predicted_labels == true_labels).sum()\n",
    "    total_samples = len(true_labels)\n",
    "    accuracy = num_correct / total_samples\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1d841ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T01:18:21.479412Z",
     "iopub.status.busy": "2023-10-31T01:18:21.479004Z",
     "iopub.status.idle": "2023-10-31T01:18:21.484550Z",
     "shell.execute_reply": "2023-10-31T01:18:21.483326Z"
    },
    "papermill": {
     "duration": 0.016328,
     "end_time": "2023-10-31T01:18:21.486712",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.470384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(y_test_pred, y_test)\n",
    "print(f\"Accuracy: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0243a960",
   "metadata": {
    "papermill": {
     "duration": 0.006927,
     "end_time": "2023-10-31T01:18:21.500913",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.493986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Closing Thoughts**\n",
    "In this notebook, we explored the essential concepts of saving and loading PyTorch models, a critical aspect of deep learning and machine learning workflows. We learned how to save the trained model's state dictionary to disk, enabling us to reuse and deploy models for various applications. Loading a pre-trained model allows us to continue training or make predictions on new data efficiently. Understanding these techniques empowers us to harness the full potential of PyTorch for building and deploying deep learning models in real-world scenarios. As you continue your journey in machine learning and deep learning, the ability to save and load models will prove invaluable, enabling you to unlock the power of your trained models for practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f51c5",
   "metadata": {
    "papermill": {
     "duration": 0.007025,
     "end_time": "2023-10-31T01:18:21.515189",
     "exception": false,
     "start_time": "2023-10-31T01:18:21.508164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Learn More**\n",
    "\n",
    "#### **Here are some of my contributions so far:**\n",
    "====================================\n",
    "- **[Mastering PyTorch Tensors: Fundamentals to Advance](https://www.kaggle.com/code/tanvirnwu/mastering-pytorch-tensors-fundamentals-to-advance)**\n",
    "- **[Comprehensive Guide on NumPy for Beginners](https://www.kaggle.com/code/tanvirnwu/comprehensive-guide-on-numpy-for-beginners#Learn-More)**\n",
    "- **[Boolean in Python with Example and Explanation](https://www.kaggle.com/code/tanvirnwu/boolean-in-python-with-example-and-explanation)**\n",
    "- **[Dictionary in Python with Examples & Explanations](https://www.kaggle.com/code/tanvirnwu/dictionary-in-python-with-examples-explanations)**\n",
    "- **[List in Python for Beginners](https://www.kaggle.com/code/tanvirnwu/list-in-python-for-beginners)**\n",
    "- **[A Brief Introduction of Graph Neural Network (GNN): Concepts, Types, and Uses](https://www.kaggle.com/discussions/general/449125#2493256)**\n",
    "- **[Essential Python Libraries for Data Visualization](https://www.kaggle.com/discussions/getting-started/450857)**\n",
    "\n",
    "#### **Thank you!!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.870655,
   "end_time": "2023-10-31T01:18:22.444376",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-31T01:18:01.573721",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
